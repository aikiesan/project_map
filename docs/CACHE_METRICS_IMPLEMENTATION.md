# Cache Performance Metrics Implementation Guide
## Three-Layer Caching System Instrumentation for CP2B Maps

**Document Version**: 1.0
**Date**: December 6, 2025
**Platform**: CP2B Maps - Biogas Potential Analysis Platform
**Purpose**: Measure and document actual cache hit rates for publication

---

## Executive Summary

This document provides a complete implementation guide for instrumenting and measuring cache performance in CP2B Maps' three-layer caching architecture. The system currently uses Streamlit's `@st.cache_resource` and `@st.cache_data` decorators across 23 files but **lacks quantitative performance metrics**.

**Deliverables**:
- Cache hit rate instrumentation code
- Performance monitoring dashboard
- Metrics collection and export functionality
- Publication-ready performance data

**Implementation Time**: 6-8 hours
**Measurement Period**: 1-2 weeks for statistically significant data

---

## Table of Contents

1. [Current State Analysis](#1-current-state-analysis)
2. [Three-Layer Caching Architecture](#2-three-layer-caching-architecture)
3. [Instrumentation Strategy](#3-instrumentation-strategy)
4. [Implementation Guide](#4-implementation-guide)
5. [Metrics Collection](#5-metrics-collection)
6. [Monitoring Dashboard](#6-monitoring-dashboard)
7. [Performance Benchmarking](#7-performance-benchmarking)
8. [Publication Reporting](#8-publication-reporting)
9. [Troubleshooting](#9-troubleshooting)

---

## 1. Current State Analysis

### 1.1 Existing Cache Usage

**Files Using Caching** (from grep results): 23 Python modules

**Cache Decorators Identified**:
- `@st.cache_resource`: Singleton objects (databases, analyzers, managers)
- `@st.cache_data`: Query results, calculations, dataframes
- Session state caching: Page instances stored in `st.session_state`

**Example from app.py**:
```python
@st.cache_resource
def initialize_accessibility():
    """Initialize accessibility manager once and cache it"""
    logger.info("Initializing accessibility manager (cached)")
    return AccessibilityManager()
```

### 1.2 Problem Statement

**Current Situation**:
- âœ… Caching is implemented
- âŒ No metrics on hit rates
- âŒ No performance data for publication
- âŒ Cannot quantify improvement over no-cache baseline

**Required for Publication**:
- Cache hit rates by layer (resource, data, session)
- Query performance improvements (cached vs uncached)
- Memory usage statistics
- Load time reductions

---

## 2. Three-Layer Caching Architecture

### 2.1 Architecture Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     User Request                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Layer 1: Session State Cache                                â”‚
â”‚  â”œâ”€ Page instances (WelcomeHomePage, HomePage, etc.)        â”‚
â”‚  â”œâ”€ User selections (municipality, scenario, filters)        â”‚
â”‚  â”œâ”€ Temporary calculations                                   â”‚
â”‚  â””â”€ Scope: Single user session                               â”‚
â”‚     Persistence: Until browser refresh                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚ Cache miss
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Layer 2: Data Cache (@st.cache_data)                       â”‚
â”‚  â”œâ”€ Query results (municipality data, statistics)           â”‚
â”‚  â”œâ”€ Calculations (biogas potential, scenarios)              â”‚
â”‚  â”œâ”€ Processed dataframes                                     â”‚
â”‚  â””â”€ Scope: All users (shared)                                â”‚
â”‚     Persistence: Until cache invalidation or app restart     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚ Cache miss
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Layer 3: Resource Cache (@st.cache_resource)               â”‚
â”‚  â”œâ”€ Database connections (DatabaseLoader)                   â”‚
â”‚  â”œâ”€ Shapefile loaders (GeospatialAnalyzer)                  â”‚
â”‚  â”œâ”€ Reference databases (ReferenceDatabase)                 â”‚
â”‚  â”œâ”€ Accessibility manager                                    â”‚
â”‚  â””â”€ Scope: All users (singleton)                             â”‚
â”‚     Persistence: Until app restart                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚ Cache miss
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Data Sources                                                 â”‚
â”‚  â”œâ”€ SQLite database (cp2b_maps.db)                          â”‚
â”‚  â”œâ”€ Shapefiles (GeoJSON)                                    â”‚
â”‚  â”œâ”€ Raster files                                             â”‚
â”‚  â””â”€ JSON data files                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 2.2 Expected Performance Characteristics

**Layer 1 (Session State)**:
- Expected hit rate: 60-80% (same user repeats actions)
- Access time: <1ms (in-memory Python objects)
- Memory impact: ~10-50 MB per session

**Layer 2 (Data Cache)**:
- Expected hit rate: 40-60% (common queries shared across users)
- Access time: <10ms (serialized data)
- Memory impact: ~100-500 MB (shared pool)

**Layer 3 (Resource Cache)**:
- Expected hit rate: 95-99% (initialized once, reused forever)
- Access time: <1ms (singleton references)
- Memory impact: ~50-200 MB (database connections, loaders)

**Overall System**:
- Expected combined hit rate: **70-85%**
- Performance improvement vs no cache: **10-50x faster**
- Memory usage: **500-750 MB** for typical workload

---

## 3. Instrumentation Strategy

### 3.1 Metrics to Collect

#### 3.1.1 Hit Rate Metrics

**Per Cache Layer**:
- Total accesses
- Cache hits
- Cache misses
- Hit rate percentage
- Hit rate by function

**Example**:
```json
{
  "layer": "resource",
  "function": "load_municipality_data",
  "total_calls": 1523,
  "hits": 1498,
  "misses": 25,
  "hit_rate": 0.984  // 98.4%
}
```

#### 3.1.2 Performance Metrics

**Timing Data**:
- Cache hit latency (time to return cached value)
- Cache miss latency (time to compute + cache)
- Cold start time (first call, no cache)

**Example**:
```json
{
  "function": "calculate_biogas_potential",
  "cold_start_ms": 245.3,
  "cache_miss_ms": 234.1,
  "cache_hit_ms": 2.1,
  "speedup": "117x faster"
}
```

#### 3.1.3 Memory Metrics

**Cache Size**:
- Number of cached items
- Memory consumed (MB)
- Eviction rate

**Example**:
```json
{
  "layer": "data",
  "cached_items": 234,
  "memory_mb": 387.2,
  "evictions_last_hour": 12
}
```

### 3.2 Measurement Approach

**Option A: Decorator Wrapper** (Recommended)
- Wrap existing `@st.cache_*` decorators with instrumentation
- Minimal code changes
- Transparent to application logic

**Option B: Manual Instrumentation**
- Add timing code around each cached function
- More invasive
- Greater control

**Option C: Hybrid**
- Decorator wrapper for most functions
- Manual instrumentation for critical paths

**Recommendation**: Use **Option A** for 90% of functions, Option C for detailed analysis.

---

## 4. Implementation Guide

### 4.1 Create Instrumentation Module

**File**: `src/utils/cache_metrics.py`

```python
"""
Cache Performance Metrics Instrumentation
Tracks hit rates, latency, and memory usage for CP2B Maps caching layers
"""

import time
import functools
import streamlit as st
from typing import Any, Callable, Dict, List
from dataclasses import dataclass, asdict
from datetime import datetime
import json
import threading
from pathlib import Path

# Thread-safe metrics storage
_metrics_lock = threading.Lock()
_metrics_data = {
    "resource": {},
    "data": {},
    "session": {}
}


@dataclass
class CacheMetric:
    """Single cache access metric"""
    function_name: str
    layer: str  # "resource", "data", or "session"
    timestamp: str
    is_hit: bool
    latency_ms: float
    cached_items: int = 0
    memory_mb: float = 0.0


@dataclass
class FunctionStats:
    """Aggregated statistics for a cached function"""
    function_name: str
    layer: str
    total_calls: int = 0
    hits: int = 0
    misses: int = 0
    hit_rate: float = 0.0
    avg_hit_latency_ms: float = 0.0
    avg_miss_latency_ms: float = 0.0
    total_time_saved_ms: float = 0.0
    first_call_time: str = ""
    last_call_time: str = ""


class CacheMetricsCollector:
    """Central collector for cache performance metrics"""

    def __init__(self, output_dir: str = "metrics"):
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(exist_ok=True)
        self.metrics_file = self.output_dir / "cache_metrics.jsonl"
        self.enabled = True

    def record_access(self, metric: CacheMetric):
        """Record a single cache access"""
        if not self.enabled:
            return

        with _metrics_lock:
            layer = metric.layer
            func = metric.function_name

            if func not in _metrics_data[layer]:
                _metrics_data[layer][func] = {
                    "hits": [],
                    "misses": [],
                    "latencies": {"hit": [], "miss": []}
                }

            if metric.is_hit:
                _metrics_data[layer][func]["hits"].append(metric.timestamp)
                _metrics_data[layer][func]["latencies"]["hit"].append(metric.latency_ms)
            else:
                _metrics_data[layer][func]["misses"].append(metric.timestamp)
                _metrics_data[layer][func]["latencies"]["miss"].append(metric.latency_ms)

        # Write to JSONL for time-series analysis
        with open(self.metrics_file, "a") as f:
            f.write(json.dumps(asdict(metric)) + "\n")

    def get_function_stats(self, function_name: str, layer: str) -> FunctionStats:
        """Get aggregated statistics for a function"""
        with _metrics_lock:
            data = _metrics_data[layer].get(function_name, {})

            if not data:
                return FunctionStats(function_name, layer)

            hits = len(data["hits"])
            misses = len(data["misses"])
            total = hits + misses

            if total == 0:
                return FunctionStats(function_name, layer)

            hit_rate = hits / total if total > 0 else 0.0

            avg_hit_latency = (
                sum(data["latencies"]["hit"]) / len(data["latencies"]["hit"])
                if data["latencies"]["hit"] else 0.0
            )

            avg_miss_latency = (
                sum(data["latencies"]["miss"]) / len(data["latencies"]["miss"])
                if data["latencies"]["miss"] else 0.0
            )

            # Estimate time saved by caching
            time_saved = hits * (avg_miss_latency - avg_hit_latency)

            first_call = min(data["hits"] + data["misses"]) if data["hits"] or data["misses"] else ""
            last_call = max(data["hits"] + data["misses"]) if data["hits"] or data["misses"] else ""

            return FunctionStats(
                function_name=function_name,
                layer=layer,
                total_calls=total,
                hits=hits,
                misses=misses,
                hit_rate=hit_rate,
                avg_hit_latency_ms=avg_hit_latency,
                avg_miss_latency_ms=avg_miss_latency,
                total_time_saved_ms=time_saved,
                first_call_time=first_call,
                last_call_time=last_call
            )

    def get_all_stats(self) -> Dict[str, List[FunctionStats]]:
        """Get statistics for all cached functions"""
        all_stats = {
            "resource": [],
            "data": [],
            "session": []
        }

        with _metrics_lock:
            for layer in _metrics_data:
                for func_name in _metrics_data[layer]:
                    stats = self.get_function_stats(func_name, layer)
                    all_stats[layer].append(stats)

        return all_stats

    def export_summary(self, filepath: str = None):
        """Export summary statistics to JSON"""
        if filepath is None:
            filepath = self.output_dir / f"cache_summary_{datetime.now():%Y%m%d_%H%M%S}.json"

        all_stats = self.get_all_stats()

        # Convert dataclasses to dicts
        export_data = {
            layer: [asdict(stat) for stat in stats]
            for layer, stats in all_stats.items()
        }

        # Add overall summary
        export_data["overall"] = self._calculate_overall_stats(all_stats)

        with open(filepath, "w") as f:
            json.dump(export_data, f, indent=2)

        return filepath

    def _calculate_overall_stats(self, all_stats: Dict) -> Dict:
        """Calculate system-wide statistics"""
        total_calls = 0
        total_hits = 0
        total_time_saved = 0.0

        for layer_stats in all_stats.values():
            for stat in layer_stats:
                total_calls += stat.total_calls
                total_hits += stat.hits
                total_time_saved += stat.total_time_saved_ms

        return {
            "total_calls": total_calls,
            "total_hits": total_hits,
            "total_misses": total_calls - total_hits,
            "overall_hit_rate": total_hits / total_calls if total_calls > 0 else 0.0,
            "total_time_saved_ms": total_time_saved,
            "total_time_saved_hours": total_time_saved / (1000 * 60 * 60)
        }


# Global collector instance
_collector = CacheMetricsCollector()


def instrumented_cache_resource(func: Callable = None, **cache_kwargs) -> Callable:
    """
    Instrumented version of @st.cache_resource

    Usage:
        @instrumented_cache_resource
        def load_database():
            return Database()
    """
    def decorator(f: Callable) -> Callable:
        # Apply Streamlit's cache_resource
        cached_func = st.cache_resource(**cache_kwargs)(f)

        @functools.wraps(f)
        def wrapper(*args, **kwargs):
            start_time = time.perf_counter()

            # Call cached function
            result = cached_func(*args, **kwargs)

            end_time = time.perf_counter()
            latency_ms = (end_time - start_time) * 1000

            # Determine if cache hit (heuristic: <5ms = likely cache hit)
            is_hit = latency_ms < 5.0

            # Record metric
            metric = CacheMetric(
                function_name=f.__name__,
                layer="resource",
                timestamp=datetime.now().isoformat(),
                is_hit=is_hit,
                latency_ms=latency_ms
            )
            _collector.record_access(metric)

            return result

        return wrapper

    if func is None:
        return decorator
    else:
        return decorator(func)


def instrumented_cache_data(func: Callable = None, **cache_kwargs) -> Callable:
    """
    Instrumented version of @st.cache_data

    Usage:
        @instrumented_cache_data
        def calculate_biogas(municipality_id):
            return complex_calculation()
    """
    def decorator(f: Callable) -> Callable:
        # Apply Streamlit's cache_data
        cached_func = st.cache_data(**cache_kwargs)(f)

        @functools.wraps(f)
        def wrapper(*args, **kwargs):
            start_time = time.perf_counter()

            # Call cached function
            result = cached_func(*args, **kwargs)

            end_time = time.perf_counter()
            latency_ms = (end_time - start_time) * 1000

            # Determine if cache hit (heuristic: <10ms = likely cache hit for data)
            is_hit = latency_ms < 10.0

            # Record metric
            metric = CacheMetric(
                function_name=f.__name__,
                layer="data",
                timestamp=datetime.now().isoformat(),
                is_hit=is_hit,
                latency_ms=latency_ms
            )
            _collector.record_access(metric)

            return result

        return wrapper

    if func is None:
        return decorator
    else:
        return decorator(func)


def get_metrics_collector() -> CacheMetricsCollector:
    """Get global metrics collector instance"""
    return _collector


# Convenience functions for Streamlit UI
def display_cache_metrics():
    """Display cache metrics in Streamlit dashboard"""
    st.subheader("ğŸ“Š Cache Performance Metrics")

    all_stats = _collector.get_all_stats()

    # Overall summary
    overall = _collector._calculate_overall_stats(all_stats)

    col1, col2, col3, col4 = st.columns(4)
    with col1:
        st.metric("Total Requests", f"{overall['total_calls']:,}")
    with col2:
        st.metric("Cache Hits", f"{overall['total_hits']:,}")
    with col3:
        st.metric("Hit Rate", f"{overall['overall_hit_rate']:.1%}")
    with col4:
        st.metric("Time Saved", f"{overall['total_time_saved_hours']:.2f}h")

    # Per-layer breakdown
    st.subheader("By Cache Layer")

    for layer in ["resource", "data", "session"]:
        with st.expander(f"ğŸ“¦ {layer.title()} Cache"):
            layer_stats = all_stats[layer]

            if not layer_stats:
                st.info(f"No metrics recorded for {layer} cache yet")
                continue

            # Create dataframe for display
            import pandas as pd
            df = pd.DataFrame([asdict(s) for s in layer_stats])

            # Format percentages
            df['hit_rate'] = df['hit_rate'].apply(lambda x: f"{x:.1%}")
            df['avg_hit_latency_ms'] = df['avg_hit_latency_ms'].apply(lambda x: f"{x:.2f}")
            df['avg_miss_latency_ms'] = df['avg_miss_latency_ms'].apply(lambda x: f"{x:.2f}")

            st.dataframe(
                df[['function_name', 'total_calls', 'hits', 'misses', 'hit_rate',
                    'avg_hit_latency_ms', 'avg_miss_latency_ms']],
                use_container_width=True
            )

    # Export button
    if st.button("ğŸ“¥ Export Metrics Summary"):
        filepath = _collector.export_summary()
        st.success(f"Metrics exported to: {filepath}")

        # Provide download link
        with open(filepath, "r") as f:
            st.download_button(
                "Download JSON",
                data=f.read(),
                file_name=filepath.name,
                mime="application/json"
            )
```

### 4.2 Update Existing Cache Decorators

**Before** (example from `src/data/loaders/database_loader.py`):
```python
import streamlit as st

@st.cache_resource
def get_database_loader():
    """Get cached database loader instance"""
    return DatabaseLoader()
```

**After** (with instrumentation):
```python
from src.utils.cache_metrics import instrumented_cache_resource

@instrumented_cache_resource
def get_database_loader():
    """Get cached database loader instance"""
    return DatabaseLoader()
```

**Migration Steps**:

1. **Add import** to each file:
```python
from src.utils.cache_metrics import instrumented_cache_resource, instrumented_cache_data
```

2. **Replace decorators**:
- `@st.cache_resource` â†’ `@instrumented_cache_resource`
- `@st.cache_data` â†’ `@instrumented_cache_data`

3. **Keep all existing parameters**:
```python
# Works with all Streamlit cache parameters
@instrumented_cache_data(ttl=3600, show_spinner=False)
def expensive_calculation():
    ...
```

### 4.3 Instrumentation Checklist

**Priority 1: Critical Path Functions** (instrument first)

- [ ] `src/data/loaders/database_loader.py::get_database_loader`
- [ ] `src/data/loaders/database_loader.py::load_municipality_data`
- [ ] `src/core/biogas_calculator.py::calculate_biogas_potential` (if cached)
- [ ] `src/core/geospatial_analysis.py::get_geospatial_analyzer`
- [ ] `src/data/loaders/shapefile_loader.py::load_shapefile`

**Priority 2: Frequently Used** (next batch)

- [ ] `src/data/references/reference_database.py::get_reference_database`
- [ ] `src/ui/utils/chart_helpers.py` (cached chart functions)
- [ ] `src/data/loaders/mapbiomas_loader.py::load_mapbiomas_data`

**Priority 3: All Remaining** (complete coverage)

- [ ] All 23 files identified in grep results

### 4.4 Session State Instrumentation

**Session state caching** (Layer 1) requires manual instrumentation.

**File**: `app.py`

**Add timing wrapper**:
```python
from src.utils.cache_metrics import CacheMetric, get_metrics_collector
from datetime import datetime
import time

def get_cached_page(page_key: str, factory_func):
    """
    Get page from session state cache with metrics

    Args:
        page_key: Session state key (e.g., "welcome_page")
        factory_func: Function to create page if not cached
    """
    collector = get_metrics_collector()
    start_time = time.perf_counter()

    # Check session state cache
    if page_key in st.session_state:
        result = st.session_state[page_key]
        is_hit = True
    else:
        result = factory_func()
        st.session_state[page_key] = result
        is_hit = False

    end_time = time.perf_counter()
    latency_ms = (end_time - start_time) * 1000

    # Record metric
    metric = CacheMetric(
        function_name=page_key,
        layer="session",
        timestamp=datetime.now().isoformat(),
        is_hit=is_hit,
        latency_ms=latency_ms
    )
    collector.record_access(metric)

    return result
```

**Usage in app.py**:
```python
# Before:
st.session_state.welcome_page = WelcomeHomePage()

# After:
st.session_state.welcome_page = get_cached_page(
    "welcome_page",
    lambda: WelcomeHomePage()
)
```

---

## 5. Metrics Collection

### 5.1 Data Collection Period

**Recommended Duration**: 14 days minimum

**Why 14 days?**
- Captures weekly usage patterns
- Includes weekday + weekend traffic
- Statistically significant sample size (>1000 requests)

**Data Quality Requirements**:
- At least 100 unique user sessions
- At least 1,000 total cache accesses
- Representative mix of municipalities queried

### 5.2 Metrics Files

**Generated Files** (in `metrics/` directory):

```
metrics/
â”œâ”€â”€ cache_metrics.jsonl          # Time-series log (one line per access)
â”œâ”€â”€ cache_summary_20251206.json  # Daily summary export
â”œâ”€â”€ cache_summary_20251213.json  # Weekly export
â””â”€â”€ publication_report.json      # Final report for paper
```

**Sample JSONL Entry**:
```json
{"function_name": "load_municipality_data", "layer": "data", "timestamp": "2025-12-06T14:32:15.123", "is_hit": true, "latency_ms": 3.2, "cached_items": 0, "memory_mb": 0.0}
{"function_name": "get_database_loader", "layer": "resource", "timestamp": "2025-12-06T14:32:15.127", "is_hit": true, "latency_ms": 0.8, "cached_items": 0, "memory_mb": 0.0}
```

**Sample Summary JSON**:
```json
{
  "resource": [
    {
      "function_name": "get_database_loader",
      "layer": "resource",
      "total_calls": 1523,
      "hits": 1522,
      "misses": 1,
      "hit_rate": 0.9993,
      "avg_hit_latency_ms": 0.85,
      "avg_miss_latency_ms": 234.5,
      "total_time_saved_ms": 356234.3,
      "first_call_time": "2025-12-01T10:00:00",
      "last_call_time": "2025-12-14T18:45:23"
    }
  ],
  "overall": {
    "total_calls": 12456,
    "total_hits": 9832,
    "total_misses": 2624,
    "overall_hit_rate": 0.789,
    "total_time_saved_ms": 2456780.5,
    "total_time_saved_hours": 0.682
  }
}
```

### 5.3 Real-Time Monitoring

**Add monitoring page** to app.py:

```python
# In app.py, add new tab:
tabs = st.tabs([
    "ğŸ  InÃ­cio",
    # ... existing tabs ...
    "ğŸ“Š Cache Metrics"  # NEW
])

with tabs[8]:  # Adjust index
    st.session_state.current_tab = "Cache Metrics"

    from src.utils.cache_metrics import display_cache_metrics
    display_cache_metrics()
```

**Features**:
- Live hit rate dashboard
- Per-function statistics table
- Export button for JSON summary
- Time-series charts (optional with plotly)

---

## 6. Monitoring Dashboard

### 6.1 Admin Dashboard Layout

**File**: `src/ui/pages/cache_dashboard.py`

```python
"""Cache Performance Monitoring Dashboard"""

import streamlit as st
import pandas as pd
import plotly.express as px
from datetime import datetime, timedelta
from src.utils.cache_metrics import get_metrics_collector

def render_cache_dashboard():
    """Render comprehensive cache performance dashboard"""

    st.title("ğŸš€ Cache Performance Dashboard")
    st.caption("Real-time monitoring of CP2B Maps caching system")

    collector = get_metrics_collector()
    all_stats = collector.get_all_stats()
    overall = collector._calculate_overall_stats(all_stats)

    # === SECTION 1: Overall Metrics ===
    st.header("ğŸ“ˆ Overall Performance")

    col1, col2, col3, col4, col5 = st.columns(5)

    with col1:
        st.metric(
            "Total Requests",
            f"{overall['total_calls']:,}",
            delta=None,
            help="Total cache access attempts"
        )

    with col2:
        st.metric(
            "Cache Hits",
            f"{overall['total_hits']:,}",
            delta=f"+{overall['total_hits'] / max(overall['total_calls'], 1) * 100:.1f}%",
            delta_color="normal",
            help="Successful cache retrievals"
        )

    with col3:
        st.metric(
            "Hit Rate",
            f"{overall['overall_hit_rate']:.1%}",
            delta=None,
            help="Percentage of requests served from cache"
        )

    with col4:
        st.metric(
            "Time Saved",
            f"{overall['total_time_saved_hours']:.2f} hrs",
            delta=None,
            help="Total computation time avoided"
        )

    with col5:
        avg_speedup = calculate_average_speedup(all_stats)
        st.metric(
            "Avg Speedup",
            f"{avg_speedup:.1f}x",
            delta=None,
            help="Average performance improvement"
        )

    # === SECTION 2: Hit Rate by Layer ===
    st.header("ğŸ¯ Hit Rate by Cache Layer")

    layer_metrics = calculate_layer_metrics(all_stats)

    fig = px.bar(
        layer_metrics,
        x='layer',
        y='hit_rate',
        color='layer',
        title='Cache Hit Rate by Layer',
        labels={'hit_rate': 'Hit Rate (%)', 'layer': 'Cache Layer'},
        text_auto='.1%'
    )
    fig.update_yaxes(range=[0, 1])
    st.plotly_chart(fig, use_container_width=True)

    # === SECTION 3: Top Functions ===
    st.header("ğŸ” Top Cached Functions")

    col1, col2 = st.columns(2)

    with col1:
        st.subheader("Most Called")
        top_called = get_top_functions_by_calls(all_stats, limit=10)
        st.dataframe(top_called, use_container_width=True)

    with col2:
        st.subheader("Highest Time Savings")
        top_savings = get_top_functions_by_time_saved(all_stats, limit=10)
        st.dataframe(top_savings, use_container_width=True)

    # === SECTION 4: Latency Analysis ===
    st.header("â±ï¸ Latency Analysis")

    latency_df = create_latency_comparison_df(all_stats)

    fig = px.scatter(
        latency_df,
        x='avg_miss_latency_ms',
        y='avg_hit_latency_ms',
        size='total_calls',
        color='layer',
        hover_data=['function_name'],
        title='Cache Hit vs Miss Latency',
        labels={
            'avg_miss_latency_ms': 'Miss Latency (ms)',
            'avg_hit_latency_ms': 'Hit Latency (ms)'
        },
        log_x=True,
        log_y=True
    )

    # Add diagonal line (y=x) for reference
    fig.add_shape(
        type="line",
        x0=0.1, y0=0.1,
        x1=1000, y1=1000,
        line=dict(dash="dash", color="gray")
    )

    st.plotly_chart(fig, use_container_width=True)
    st.caption("Points below diagonal indicate cache provides speedup")

    # === SECTION 5: Detailed Function Table ===
    st.header("ğŸ“‹ Detailed Function Statistics")

    all_functions_df = create_all_functions_df(all_stats)

    st.dataframe(
        all_functions_df,
        use_container_width=True,
        column_config={
            "hit_rate": st.column_config.ProgressColumn(
                "Hit Rate",
                format="%.1f%%",
                min_value=0,
                max_value=100
            ),
            "speedup": st.column_config.NumberColumn(
                "Speedup",
                format="%.1fx"
            )
        }
    )

    # === SECTION 6: Export ===
    st.header("ğŸ’¾ Export Metrics")

    col1, col2, col3 = st.columns(3)

    with col1:
        if st.button("ğŸ“¥ Export JSON Summary"):
            filepath = collector.export_summary()
            with open(filepath, "r") as f:
                st.download_button(
                    "Download JSON",
                    data=f.read(),
                    file_name=filepath.name,
                    mime="application/json"
                )

    with col2:
        if st.button("ğŸ“Š Export CSV"):
            csv_data = all_functions_df.to_csv(index=False)
            st.download_button(
                "Download CSV",
                data=csv_data,
                file_name=f"cache_metrics_{datetime.now():%Y%m%d}.csv",
                mime="text/csv"
            )

    with col3:
        if st.button("ğŸ“„ Generate Publication Report"):
            report_path = generate_publication_report(all_stats, overall)
            st.success(f"Report generated: {report_path}")


# Helper functions

def calculate_average_speedup(all_stats):
    """Calculate average speedup across all functions"""
    total_speedup = 0
    count = 0

    for layer_stats in all_stats.values():
        for stat in layer_stats:
            if stat.avg_hit_latency_ms > 0 and stat.avg_miss_latency_ms > 0:
                speedup = stat.avg_miss_latency_ms / stat.avg_hit_latency_ms
                total_speedup += speedup
                count += 1

    return total_speedup / count if count > 0 else 0


def calculate_layer_metrics(all_stats):
    """Calculate metrics by cache layer"""
    layer_data = []

    for layer, stats_list in all_stats.items():
        total_calls = sum(s.total_calls for s in stats_list)
        total_hits = sum(s.hits for s in stats_list)
        hit_rate = total_hits / total_calls if total_calls > 0 else 0

        layer_data.append({
            'layer': layer.title(),
            'total_calls': total_calls,
            'hits': total_hits,
            'hit_rate': hit_rate
        })

    return pd.DataFrame(layer_data)


def get_top_functions_by_calls(all_stats, limit=10):
    """Get top N functions by call count"""
    all_functions = []

    for layer_stats in all_stats.values():
        all_functions.extend(layer_stats)

    sorted_funcs = sorted(all_functions, key=lambda x: x.total_calls, reverse=True)

    return pd.DataFrame([
        {
            'Function': s.function_name,
            'Layer': s.layer,
            'Calls': s.total_calls,
            'Hit Rate': f"{s.hit_rate:.1%}"
        }
        for s in sorted_funcs[:limit]
    ])


def get_top_functions_by_time_saved(all_stats, limit=10):
    """Get top N functions by time saved"""
    all_functions = []

    for layer_stats in all_stats.values():
        all_functions.extend(layer_stats)

    sorted_funcs = sorted(all_functions, key=lambda x: x.total_time_saved_ms, reverse=True)

    return pd.DataFrame([
        {
            'Function': s.function_name,
            'Layer': s.layer,
            'Time Saved': f"{s.total_time_saved_ms / 1000:.2f}s",
            'Hit Rate': f"{s.hit_rate:.1%}"
        }
        for s in sorted_funcs[:limit]
    ])


def create_latency_comparison_df(all_stats):
    """Create dataframe comparing hit vs miss latency"""
    rows = []

    for layer, stats_list in all_stats.items():
        for stat in stats_list:
            if stat.total_calls > 0:
                rows.append({
                    'function_name': stat.function_name,
                    'layer': layer,
                    'total_calls': stat.total_calls,
                    'avg_hit_latency_ms': max(stat.avg_hit_latency_ms, 0.1),
                    'avg_miss_latency_ms': max(stat.avg_miss_latency_ms, 0.1)
                })

    return pd.DataFrame(rows)


def create_all_functions_df(all_stats):
    """Create comprehensive dataframe of all functions"""
    rows = []

    for layer, stats_list in all_stats.items():
        for stat in stats_list:
            speedup = (
                stat.avg_miss_latency_ms / stat.avg_hit_latency_ms
                if stat.avg_hit_latency_ms > 0 else 0
            )

            rows.append({
                'Function': stat.function_name,
                'Layer': stat.layer,
                'Calls': stat.total_calls,
                'Hits': stat.hits,
                'Misses': stat.misses,
                'hit_rate': stat.hit_rate * 100,
                'Hit Latency (ms)': f"{stat.avg_hit_latency_ms:.2f}",
                'Miss Latency (ms)': f"{stat.avg_miss_latency_ms:.2f}",
                'speedup': speedup,
                'Time Saved (s)': f"{stat.total_time_saved_ms / 1000:.2f}"
            })

    return pd.DataFrame(rows)


def generate_publication_report(all_stats, overall):
    """Generate formatted report for academic publication"""
    report = {
        "title": "CP2B Maps Cache Performance Report",
        "generation_date": datetime.now().isoformat(),
        "measurement_period": "14 days",

        "executive_summary": {
            "overall_hit_rate": f"{overall['overall_hit_rate']:.1%}",
            "total_requests": overall['total_calls'],
            "total_time_saved_hours": round(overall['total_time_saved_hours'], 2),
            "average_speedup": f"{calculate_average_speedup(all_stats):.1f}x"
        },

        "layer_performance": {
            "resource_cache": get_layer_summary(all_stats['resource']),
            "data_cache": get_layer_summary(all_stats['data']),
            "session_cache": get_layer_summary(all_stats['session'])
        },

        "top_functions": {
            "most_called": [
                {
                    "name": s.function_name,
                    "calls": s.total_calls,
                    "hit_rate": f"{s.hit_rate:.1%}"
                }
                for s in sorted(
                    [s for layer in all_stats.values() for s in layer],
                    key=lambda x: x.total_calls,
                    reverse=True
                )[:5]
            ],
            "highest_speedup": get_highest_speedup_functions(all_stats, 5)
        }
    }

    # Save to file
    from pathlib import Path
    output_dir = Path("metrics")
    output_dir.mkdir(exist_ok=True)
    filepath = output_dir / "publication_report.json"

    with open(filepath, "w") as f:
        json.dump(report, f, indent=2)

    return filepath


def get_layer_summary(layer_stats):
    """Get summary statistics for a cache layer"""
    if not layer_stats:
        return {"hit_rate": "N/A", "total_calls": 0}

    total_calls = sum(s.total_calls for s in layer_stats)
    total_hits = sum(s.hits for s in layer_stats)
    hit_rate = total_hits / total_calls if total_calls > 0 else 0

    avg_hit_latency = sum(s.avg_hit_latency_ms for s in layer_stats) / len(layer_stats)
    avg_miss_latency = sum(s.avg_miss_latency_ms for s in layer_stats) / len(layer_stats)

    return {
        "hit_rate": f"{hit_rate:.1%}",
        "total_calls": total_calls,
        "avg_hit_latency_ms": round(avg_hit_latency, 2),
        "avg_miss_latency_ms": round(avg_miss_latency, 2),
        "speedup": f"{avg_miss_latency / avg_hit_latency:.1f}x" if avg_hit_latency > 0 else "N/A"
    }


def get_highest_speedup_functions(all_stats, limit=5):
    """Get functions with highest speedup ratios"""
    all_functions = []

    for layer_stats in all_stats.values():
        for stat in layer_stats:
            if stat.avg_hit_latency_ms > 0 and stat.avg_miss_latency_ms > 0:
                speedup = stat.avg_miss_latency_ms / stat.avg_hit_latency_ms
                all_functions.append({
                    "name": stat.function_name,
                    "speedup": f"{speedup:.1f}x",
                    "hit_latency_ms": round(stat.avg_hit_latency_ms, 2),
                    "miss_latency_ms": round(stat.avg_miss_latency_ms, 2)
                })

    sorted_functions = sorted(
        all_functions,
        key=lambda x: float(x['speedup'].replace('x', '')),
        reverse=True
    )

    return sorted_functions[:limit]
```

---

## 7. Performance Benchmarking

### 7.1 Baseline Measurement (No Cache)

**Temporarily disable caching** to establish baseline:

```python
# Create benchmark script: scripts/benchmark_no_cache.py

import time
import sys
from pathlib import Path

# Add src to path
sys.path.insert(0, str(Path(__file__).parent.parent / "src"))

from data.loaders.database_loader import DatabaseLoader
from core.geospatial_analysis import GeospatialAnalyzer

def benchmark_database_load():
    """Measure database load time without caching"""
    times = []

    for i in range(10):
        start = time.perf_counter()
        loader = DatabaseLoader()  # Create new instance each time
        data = loader.load_all_municipalities()
        end = time.perf_counter()

        times.append((end - start) * 1000)  # Convert to ms
        print(f"Iteration {i+1}: {times[-1]:.2f} ms")

    avg_time = sum(times) / len(times)
    print(f"\nAverage load time (no cache): {avg_time:.2f} ms")
    return avg_time


def benchmark_biogas_calculation():
    """Measure biogas calculation time without caching"""
    from core.biogas_calculator import BiogasCalculator

    loader = DatabaseLoader()
    data = loader.load_municipality_data(municipality_id=3538709)  # Piracicaba

    times = []

    for i in range(10):
        calculator = BiogasCalculator()  # New instance

        start = time.perf_counter()
        result = calculator.calculate_total_potential(data)
        end = time.perf_counter()

        times.append((end - start) * 1000)
        print(f"Iteration {i+1}: {times[-1]:.2f} ms")

    avg_time = sum(times) / len(times)
    print(f"\nAverage calculation time (no cache): {avg_time:.2f} ms")
    return avg_time


if __name__ == "__main__":
    print("=" * 60)
    print("BASELINE PERFORMANCE BENCHMARK (NO CACHING)")
    print("=" * 60)

    print("\n1. Database Load Benchmark")
    print("-" * 60)
    db_baseline = benchmark_database_load()

    print("\n2. Biogas Calculation Benchmark")
    print("-" * 60)
    calc_baseline = benchmark_biogas_calculation()

    print("\n" + "=" * 60)
    print("BASELINE SUMMARY")
    print("=" * 60)
    print(f"Database Load: {db_baseline:.2f} ms")
    print(f"Biogas Calculation: {calc_baseline:.2f} ms")
    print(f"Total: {db_baseline + calc_baseline:.2f} ms")
```

**Run baseline**:
```bash
python scripts/benchmark_no_cache.py > metrics/baseline_no_cache.txt
```

### 7.2 Cached Performance Measurement

**With caching enabled**:

```python
# Create benchmark script: scripts/benchmark_with_cache.py

import time
import sys
from pathlib import Path

sys.path.insert(0, str(Path(__file__).parent.parent / "src"))

# Import instrumented versions
from data.loaders.database_loader import get_database_loader
from core.biogas_calculator import BiogasCalculator

def benchmark_cached_database_load():
    """Measure database load time WITH caching"""
    times = []

    for i in range(10):
        start = time.perf_counter()
        loader = get_database_loader()  # Uses @cache_resource
        data = loader.load_all_municipalities()
        end = time.perf_counter()

        times.append((end - start) * 1000)
        print(f"Iteration {i+1}: {times[-1]:.2f} ms")

    # First call is cache miss, rest are hits
    first_call = times[0]
    cached_calls = times[1:]
    avg_cached = sum(cached_calls) / len(cached_calls)

    print(f"\nFirst call (miss): {first_call:.2f} ms")
    print(f"Average cached call: {avg_cached:.2f} ms")
    print(f"Speedup: {first_call / avg_cached:.1f}x")

    return first_call, avg_cached


if __name__ == "__main__":
    print("=" * 60)
    print("CACHED PERFORMANCE BENCHMARK")
    print("=" * 60)

    print("\n1. Database Load Benchmark (Cached)")
    print("-" * 60)
    miss_time, hit_time = benchmark_cached_database_load()

    print("\n" + "=" * 60)
    print("CACHE EFFECTIVENESS")
    print("=" * 60)
    print(f"Cache Miss: {miss_time:.2f} ms")
    print(f"Cache Hit: {hit_time:.2f} ms")
    print(f"Speedup: {miss_time / hit_time:.1f}x")
    print(f"Time saved per hit: {miss_time - hit_time:.2f} ms")
```

**Run cached benchmark**:
```bash
python scripts/benchmark_with_cache.py > metrics/cached_performance.txt
```

### 7.3 Load Testing

**Simulate multiple users** to stress-test cache:

```python
# Create load test: scripts/load_test.py

import concurrent.futures
import time
import random
from pathlib import Path
import sys

sys.path.insert(0, str(Path(__file__).parent.parent / "src"))

from data.loaders.database_loader import get_database_loader

# Sample municipality IDs (SÃ£o Paulo state)
MUNICIPALITY_IDS = [
    3538709,  # Piracicaba
    3509502,  # Campinas
    3550308,  # SÃ£o Paulo
    3552205,  # Sorocaba
    3518800,  # Guarulhos
    # Add more...
]

def simulate_user_session(user_id, num_queries=10):
    """Simulate a single user session"""
    loader = get_database_loader()

    query_times = []

    for i in range(num_queries):
        # Random municipality (simulates browsing)
        muni_id = random.choice(MUNICIPALITY_IDS)

        start = time.perf_counter()
        data = loader.load_municipality_data(muni_id)
        end = time.perf_counter()

        query_times.append((end - start) * 1000)

        # Simulate user think time
        time.sleep(random.uniform(0.5, 2.0))

    avg_time = sum(query_times) / len(query_times)
    print(f"User {user_id}: {num_queries} queries, avg {avg_time:.2f} ms")

    return query_times


def run_load_test(num_users=10, queries_per_user=10):
    """Run concurrent load test"""
    print(f"Starting load test: {num_users} users, {queries_per_user} queries each")
    print("=" * 60)

    start_time = time.perf_counter()

    with concurrent.futures.ThreadPoolExecutor(max_workers=num_users) as executor:
        futures = [
            executor.submit(simulate_user_session, i, queries_per_user)
            for i in range(num_users)
        ]

        all_times = []
        for future in concurrent.futures.as_completed(futures):
            times = future.result()
            all_times.extend(times)

    end_time = time.perf_counter()
    total_duration = end_time - start_time

    # Calculate statistics
    avg_query_time = sum(all_times) / len(all_times)
    min_time = min(all_times)
    max_time = max(all_times)

    print("\n" + "=" * 60)
    print("LOAD TEST RESULTS")
    print("=" * 60)
    print(f"Total users: {num_users}")
    print(f"Total queries: {len(all_times)}")
    print(f"Total duration: {total_duration:.2f}s")
    print(f"Queries/second: {len(all_times) / total_duration:.2f}")
    print(f"Average query time: {avg_query_time:.2f} ms")
    print(f"Min query time: {min_time:.2f} ms")
    print(f"Max query time: {max_time:.2f} ms")


if __name__ == "__main__":
    run_load_test(num_users=20, queries_per_user=10)
```

**Run load test**:
```bash
python scripts/load_test.py > metrics/load_test_results.txt
```

---

## 8. Publication Reporting

### 8.1 Final Report Structure

**File**: `metrics/publication_report.json`

```json
{
  "title": "CP2B Maps Three-Layer Caching System Performance Report",
  "generation_date": "2025-12-20T15:30:00",
  "measurement_period": "14 days (2025-12-06 to 2025-12-20)",
  "total_user_sessions": 1247,
  "unique_users": 342,

  "executive_summary": {
    "overall_hit_rate": "78.9%",
    "total_cache_accesses": 45623,
    "total_cache_hits": 36006,
    "total_cache_misses": 9617,
    "total_time_saved_hours": 12.45,
    "average_speedup": "23.7x",
    "memory_footprint_mb": 587
  },

  "layer_1_session_cache": {
    "description": "User session state cache for page instances",
    "hit_rate": "82.3%",
    "total_accesses": 12456,
    "avg_hit_latency_ms": 0.8,
    "avg_miss_latency_ms": 125.4,
    "speedup": "156.8x",
    "key_functions": [
      {
        "name": "welcome_page",
        "hit_rate": "85.2%",
        "calls": 3421
      },
      {
        "name": "map_page",
        "hit_rate": "79.8%",
        "calls": 5234
      }
    ]
  },

  "layer_2_data_cache": {
    "description": "Query results and calculations cache",
    "hit_rate": "64.7%",
    "total_accesses": 23789,
    "avg_hit_latency_ms": 3.2,
    "avg_miss_latency_ms": 156.8,
    "speedup": "49.0x",
    "key_functions": [
      {
        "name": "load_municipality_data",
        "hit_rate": "68.4%",
        "calls": 8934,
        "time_saved_ms": 1234567
      },
      {
        "name": "calculate_biogas_potential",
        "hit_rate": "61.2%",
        "calls": 7654,
        "time_saved_ms": 987654
      }
    ]
  },

  "layer_3_resource_cache": {
    "description": "Singleton database connections and loaders",
    "hit_rate": "99.8%",
    "total_accesses": 9378,
    "avg_hit_latency_ms": 0.6,
    "avg_miss_latency_ms": 234.5,
    "speedup": "390.8x",
    "key_functions": [
      {
        "name": "get_database_loader",
        "hit_rate": "99.9%",
        "calls": 4523,
        "time_saved_ms": 1056789
      },
      {
        "name": "get_geospatial_analyzer",
        "hit_rate": "99.7%",
        "calls": 3456,
        "time_saved_ms": 809234
      }
    ]
  },

  "baseline_comparison": {
    "description": "Performance vs no-cache baseline",
    "baseline_query_time_ms": 389.2,
    "cached_query_time_ms": 16.4,
    "improvement_factor": "23.7x",
    "baseline_total_time_hours": 13.5,
    "cached_total_time_hours": 0.57,
    "time_saved_percentage": "95.8%"
  },

  "load_test_results": {
    "concurrent_users": 20,
    "total_queries": 200,
    "queries_per_second": 43.2,
    "avg_response_time_ms": 18.7,
    "p95_response_time_ms": 45.3,
    "p99_response_time_ms": 87.1,
    "zero_errors": true
  },

  "memory_analysis": {
    "layer_1_session_mb": 42,
    "layer_2_data_mb": 412,
    "layer_3_resource_mb": 133,
    "total_cache_mb": 587,
    "memory_efficiency_mb_per_1000_hits": 16.3
  },

  "publication_summary": {
    "recommended_text": "The three-layer caching architecture achieved an overall hit rate of 78.9% across 45,623 accesses over a 14-day period, resulting in a 23.7x average speedup and 12.45 hours of computation time saved. Layer 3 (resource cache) demonstrated the highest hit rate at 99.8%, while Layer 2 (data cache) provided substantial query performance improvements with a 64.7% hit rate."
  }
}
```

### 8.2 Paper Text Template

**For Methods Section (2.5 - System Architecture)**:

```markdown
### 2.5.3 Three-Layer Caching Architecture

To optimize performance and reduce computational overhead, CP2B Maps implements
a three-layer caching strategy:

**Layer 1 (Session Cache)**: User-specific state cached in browser session,
including page instances and temporary selections. This layer achieved an
82.3% hit rate (n=12,456 accesses) with sub-millisecond retrieval times.

**Layer 2 (Data Cache)**: Shared query results and calculations cached across
all users using Streamlit's `@cache_data` decorator. This layer served 64.7%
of data requests from cache (n=23,789 accesses), reducing average query time
from 156.8 ms to 3.2 ms (49.0x speedup).

**Layer 3 (Resource Cache)**: Singleton database connections and geospatial
analyzers cached for application lifetime. This layer demonstrated 99.8% hit
rate (n=9,378 accesses), eliminating repeated expensive initialization
operations.

**Overall System Performance**: The combined caching strategy achieved 78.9%
hit rate across 45,623 total accesses during a 14-day measurement period
(Dec 6-20, 2025). This resulted in an average 23.7x performance improvement
compared to no-cache baseline, saving 12.45 hours of computation time. Under
load testing with 20 concurrent users, the system maintained 43.2 queries/second
with P95 response time of 45.3 ms.
```

**For Results Section (3.4 - System Performance)**:

```markdown
### 3.4.2 Cache Performance Analysis

Table X: Cache Hit Rates by Layer

| Cache Layer | Hit Rate | Avg Hit Latency | Avg Miss Latency | Speedup |
|-------------|----------|-----------------|------------------|---------|
| Session (L1) | 82.3% | 0.8 ms | 125.4 ms | 156.8x |
| Data (L2) | 64.7% | 3.2 ms | 156.8 ms | 49.0x |
| Resource (L3) | 99.8% | 0.6 ms | 234.5 ms | 390.8x |
| **Overall** | **78.9%** | **2.1 ms** | **165.7 ms** | **23.7x** |

The resource cache (L3) demonstrated near-perfect hit rates due to singleton
pattern, while the data cache (L2) showed more variability reflecting diverse
user query patterns. Session cache (L1) hit rates correlate with user
engagement depth (users exploring multiple municipalities within same session).

Memory consumption remained stable at 587 MB (16.3 MB per 1,000 cache hits),
indicating efficient cache management without memory leaks. Load testing with
20 concurrent users showed linear scalability with no cache thrashing observed.
```

### 8.3 Supplementary Materials Table

**Table S3: Detailed Cache Performance Metrics**

```
Function Name                    | Layer    | Calls  | Hits  | Hit Rate | Time Saved (s)
---------------------------------|----------|--------|-------|----------|---------------
get_database_loader             | Resource | 4,523  | 4,518 | 99.9%    | 1,056.8
load_municipality_data          | Data     | 8,934  | 6,109 | 68.4%    | 1,234.6
calculate_biogas_potential      | Data     | 7,654  | 4,684 | 61.2%    | 987.7
get_geospatial_analyzer         | Resource | 3,456  | 3,446 | 99.7%    | 809.2
get_reference_database          | Resource | 1,234  | 1,232 | 99.8%    | 287.9
load_mapbiomas_data             | Data     | 2,345  | 1,502 | 64.0%    | 456.3
calculate_scenario_adjustment   | Data     | 5,678  | 3,520 | 62.0%    | 678.4
...                             | ...      | ...    | ...   | ...      | ...
**TOTAL**                        | **All**  |**45,623**|**36,006**|**78.9%**|**44,820.5**
```

---

## 9. Troubleshooting

### 9.1 Common Issues

#### Issue: Hit rate always 100%

**Cause**: Cache never being invalidated, or heuristic threshold too high.

**Solution**:
```python
# In cache_metrics.py, adjust heuristic thresholds
is_hit = latency_ms < 5.0  # Lower threshold for resource cache
is_hit = latency_ms < 2.0  # More aggressive detection
```

#### Issue: Metrics not being recorded

**Cause**: Instrumentation not applied, or collector disabled.

**Solution**:
```python
# Check collector is enabled
from src.utils.cache_metrics import get_metrics_collector
collector = get_metrics_collector()
print(f"Collector enabled: {collector.enabled}")

# Enable explicitly
collector.enabled = True
```

#### Issue: Memory usage growing unboundedly

**Cause**: Metrics stored in memory without eviction.

**Solution**:
```python
# Add periodic cleanup to CacheMetricsCollector
def cleanup_old_metrics(self, days=7):
    """Remove metrics older than N days"""
    cutoff = datetime.now() - timedelta(days=days)

    with _metrics_lock:
        for layer in _metrics_data:
            for func in _metrics_data[layer]:
                # Filter out old timestamps
                # Implementation details...
```

### 9.2 Validation Checklist

Before trusting metrics:

- [ ] Instrumentation applied to all cached functions (check grep results)
- [ ] Metrics file (`cache_metrics.jsonl`) is growing
- [ ] Hit rates are realistic (not 0% or 100% for data cache)
- [ ] Latency measurements make sense (hits < misses)
- [ ] Dashboard displays data correctly
- [ ] Export functions work
- [ ] Load test completes without errors

---

## 10. Next Steps

### 10.1 Implementation Timeline

**Week 1: Setup**
- Day 1-2: Create `cache_metrics.py` module
- Day 3-4: Instrument top 10 critical functions
- Day 5: Add monitoring dashboard page
- Day 6-7: Validate instrumentation, fix bugs

**Week 2: Data Collection**
- Day 8-21: Let application run, collect metrics (14 days)
- Promote usage to get diverse queries

**Week 3: Analysis**
- Day 22-23: Run baseline and cached benchmarks
- Day 24: Run load tests
- Day 25: Generate publication report
- Day 26-27: Write paper text, create tables
- Day 28: Final review and validation

### 10.2 Deliverables Checklist

- [ ] `src/utils/cache_metrics.py` - Instrumentation module
- [ ] `src/ui/pages/cache_dashboard.py` - Monitoring dashboard
- [ ] `metrics/cache_metrics.jsonl` - Raw time-series data (14 days)
- [ ] `metrics/publication_report.json` - Final performance report
- [ ] `metrics/baseline_no_cache.txt` - Baseline benchmark results
- [ ] `metrics/cached_performance.txt` - Cached benchmark results
- [ ] `metrics/load_test_results.txt` - Load test results
- [ ] `scripts/benchmark_*.py` - Reproducible benchmark scripts
- [ ] Paper text updates (Methods section 2.5.3)
- [ ] Supplementary materials (Table S3)

---

## Appendix A: Quick Start

**Fastest path to get metrics**:

1. **Copy-paste instrumentation module**:
   - Create `src/utils/cache_metrics.py` with code from Section 4.1

2. **Update one critical file**:
   ```python
   # src/data/loaders/database_loader.py
   from src.utils.cache_metrics import instrumented_cache_resource

   @instrumented_cache_resource  # Changed from @st.cache_resource
   def get_database_loader():
       return DatabaseLoader()
   ```

3. **Add dashboard tab**:
   ```python
   # In app.py
   from src.utils.cache_metrics import display_cache_metrics

   with tabs[8]:  # New "Cache Metrics" tab
       display_cache_metrics()
   ```

4. **Run application and use it for 1 week**

5. **Export metrics**:
   - Navigate to Cache Metrics tab
   - Click "Generate Publication Report"
   - Download `publication_report.json`

6. **Done!** Use metrics in your paper.

---

**Document End**

**Version**: 1.0
**Last Updated**: December 6, 2025
**Maintained By**: CP2B Maps Development Team
**Questions**: See troubleshooting section or open GitHub issue
